{"cells":[{"cell_type":"markdown","id":"96c26cd0","metadata":{"id":"96c26cd0"},"source":["# 오차 역전파 - Backpropagation\n","[Backpropagation](https://wikidocs.net/37406)"]},{"cell_type":"markdown","id":"PNRK9E5mcSOG","metadata":{"id":"PNRK9E5mcSOG"},"source":["X - w -> Y - J -> Y'  \n","w: Weight  \n","J: Loss Function  \n","오차역전파는 dJ/dw가 0에 가까워지는 w, 즉, J를 가장 작게 만들어줄 w를 찾는 것이다. w를 찾았으면, 그 이전 노드 단계에서의 w를 찾고, 찾았으면 그 이전의 것을 찾고... 반복하는 것이다.  "]},{"cell_type":"markdown","id":"c0c93566","metadata":{"id":"c0c93566"},"source":["---"]},{"cell_type":"code","execution_count":null,"id":"f758a8dd","metadata":{"id":"f758a8dd"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.rc('figure', figsize=(10, 6))\n","\n","from matplotlib import rcParams\n","rcParams['font.family'] = 'New Gulim'\n","rcParams['font.size'] = 10\n","rcParams['axes.unicode_minus'] = False"]},{"cell_type":"markdown","id":"01f3855a","metadata":{"id":"01f3855a"},"source":["# 1 계산 그래프 - Computational graph\n","- 노드(node)\n","- 에지(edge)"]},{"cell_type":"markdown","id":"e0abdba7","metadata":{"id":"e0abdba7"},"source":["### 1.1 계산 그래프 예제"]},{"cell_type":"markdown","id":"bdc0a652","metadata":{"id":"bdc0a652"},"source":["#### 문제1) 1개에 100원인 사과를 2개 샀다. 단 소비세는 10%이다."]},{"cell_type":"markdown","id":"66568f9b","metadata":{"id":"66568f9b"},"source":["- 계산 그래프 적용\n","<img src=\"./images/fig_5-1.png\" width=\"500\"/>"]},{"cell_type":"markdown","id":"2accd355","metadata":{"id":"2accd355"},"source":["- 사과의 개수와 소비세를 변수로 설정\n","<img src=\"./images/fig_5-2.png\" width=\"500\"/>"]},{"cell_type":"markdown","id":"72cfcf60","metadata":{"id":"72cfcf60"},"source":["#### 문제2) 1개에 100원인 사과를 2개, 1개에 150원인 귤 3개를 샀다. 단 소비세는 10%이다."]},{"cell_type":"markdown","id":"e6eb8350","metadata":{"id":"e6eb8350"},"source":["- 계산 그래프 적용\n","<img src=\"./images/fig_5-3.png\" width=\"500\"/>"]},{"cell_type":"markdown","id":"5790caf9","metadata":{"id":"5790caf9"},"source":["### 1.2 계산 그래프의 특징"]},{"cell_type":"markdown","id":"93e61dae","metadata":{"id":"93e61dae"},"source":["- 중간 계산 결과 보관 가능"]},{"cell_type":"markdown","id":"c01ca31f","metadata":{"id":"c01ca31f"},"source":["- 국소적 계산\n","<img src=\"./images/fig_5-4.png\" width=\"500\"/>"]},{"cell_type":"markdown","id":"fd279023","metadata":{"id":"fd279023"},"source":["- 역전파에 의한 미분 값의 전달(미분을 효율적으로 계산)\n","<img src=\"./images/fig_5-5.png\" width=\"500\"/>"]},{"cell_type":"markdown","id":"c8247952","metadata":{"id":"c8247952"},"source":["# 2 연쇄법칙 - Chain rule"]},{"cell_type":"markdown","id":"13148533","metadata":{"id":"13148533"},"source":["### 2.1 계산 그래프의 역전파"]},{"cell_type":"markdown","id":"7d0b7f5a","metadata":{"id":"7d0b7f5a"},"source":["- $y = f(x)$\n","<img src=\"./images/fig_5-6.png\" width=\"300\"/>"]},{"cell_type":"markdown","id":"524568cd","metadata":{"id":"524568cd"},"source":["### 2.2 합성 함수의 미분"]},{"cell_type":"markdown","id":"0f9ffcf9","metadata":{"id":"0f9ffcf9"},"source":["- $z = (x + y)^2$"]},{"cell_type":"markdown","id":"3dfe8fd6","metadata":{"id":"3dfe8fd6"},"source":["- 합성 함수의 분해 - 치환\n","<img src=\"./images/e_5.1.png\" width=\"100\"/>"]},{"cell_type":"markdown","id":"8a1e2cb8","metadata":{"id":"8a1e2cb8"},"source":["- 연쇄법칙(Chain rule) 적용\n","<img src=\"./images/e_5.2.png\" width=\"150\"/>"]},{"cell_type":"markdown","id":"b41e4a89","metadata":{"id":"b41e4a89"},"source":["- 각 함수 미분\n","<img src=\"./images/e_5.3.png\" width=\"100\"/>"]},{"cell_type":"markdown","id":"9e0e75c1","metadata":{"id":"9e0e75c1"},"source":["- 합성 함수 미분 계산 - 치환 변수 환원( $t = x + y$ )\n","<img src=\"./images/e_5.4.png\" width=\"300\"/>"]},{"cell_type":"markdown","id":"8c156db7","metadata":{"id":"8c156db7"},"source":["### 2.3 연쇄법칙과 계산 그래프"]},{"cell_type":"markdown","id":"8e04c60f","metadata":{"id":"8e04c60f"},"source":["- 연쇄법칙을 계산 그래프에 적용\n","<img src=\"./images/fig_5-7.png\" width=\"400\"/>"]},{"cell_type":"markdown","id":"6e935bdd","metadata":{"id":"6e935bdd"},"source":["- 연쇄법칙과 계산 그래프를 통해 합성 함수의 미분 구현\n","- $z = (x + y)^2$\n","<img src=\"./images/fig_5-8.png\" width=\"400\"/>"]},{"cell_type":"markdown","id":"49ad7243","metadata":{"id":"49ad7243"},"source":["# 3 역전파"]},{"cell_type":"markdown","id":"140ffda0","metadata":{"id":"140ffda0"},"source":["### 3.1 덧셈 노드의 역전파"]},{"cell_type":"markdown","id":"32d1387e","metadata":{"id":"32d1387e"},"source":["- 국소적 계산\n","<img src=\"./images/fig_5-10.png\" width=\"500\"/>"]},{"cell_type":"markdown","id":"0daef521","metadata":{"id":"0daef521"},"source":["#### 3.2.1 덧셈 노드의 역전파 구현"]},{"cell_type":"markdown","id":"966a09a4","metadata":{"id":"966a09a4"},"source":["- 함수\n","$$z = x + y$$"]},{"cell_type":"markdown","id":"d2cc087f","metadata":{"id":"d2cc087f"},"source":["- 함수의 편미분\n","<img src=\"./images/e_5.5.png\" width=\"70\"/>"]},{"cell_type":"markdown","id":"33902450","metadata":{"id":"33902450"},"source":["- 덧셈 노드의 순전파와 역전파: *덧셈 노드의 역전파는 입력값을 그대로 흘려 보낸다.*\n","<img src=\"./images/fig_5-9.png\" width=\"500\"/>"]},{"cell_type":"markdown","id":"ea465f92","metadata":{"id":"ea465f92"},"source":["- 덧셈 노드의 구체적인 예\n","<img src=\"./images/fig_5-11.png\" width=\"500\"/>"]},{"cell_type":"markdown","id":"b189bc57","metadata":{"id":"b189bc57"},"source":["### 3.2 곱셈 노드의 역전파"]},{"cell_type":"markdown","id":"4b483ef8","metadata":{"id":"4b483ef8"},"source":["- 함수\n","$$z = xy$$"]},{"cell_type":"markdown","id":"86b207a9","metadata":{"id":"86b207a9"},"source":["- 함수의 편미분\n","<img src=\"./images/e_5.6.png\" width=\"70\"/>"]},{"cell_type":"markdown","id":"730ea26b","metadata":{"id":"730ea26b"},"source":["- 곱셈 노드의 순전파와 역전파: *곱셈 노드의 역전파는 입력값을 서로 바꾸고 곱해서 흘려 보낸다.*\n","<img src=\"./images/fig_5-12.png\" width=\"500\"/>"]},{"cell_type":"markdown","id":"c33a1a98","metadata":{"id":"c33a1a98"},"source":["- 곱셈 노드의 구체적인 예\n","<img src=\"./images/fig_5-13.png\" width=\"500\"/>"]},{"cell_type":"markdown","id":"e7a7620a","metadata":{"id":"e7a7620a"},"source":["### 3.3 사과 쇼핑의 예"]},{"cell_type":"markdown","id":"434f030e","metadata":{"id":"434f030e"},"source":["- 사과 쇼핑의 역전파 예\n","<img src=\"./images/fig_5-14.png\" width=\"500\"/>"]},{"cell_type":"markdown","id":"f15b6c1d","metadata":{"id":"f15b6c1d"},"source":["- 사과와 귤 쇼핑의 역전파 예 - 문제\n","<img src=\"./images/fig_5-15.png\" width=\"500\"/>"]},{"cell_type":"markdown","id":"d1a08b3c","metadata":{"id":"d1a08b3c"},"source":["- 사과와 귤 쇼핑의 역전파 예 - 정답\n","<img src=\"./images/fig_5-17.png\" width=\"500\"/>"]},{"cell_type":"markdown","id":"2ce34df4","metadata":{"id":"2ce34df4"},"source":["# 4 연산 계층 코드 구현\n","- AddLayer\n","- MulLayer"]},{"cell_type":"markdown","id":"ff3a8434","metadata":{"id":"ff3a8434"},"source":["### 4.1 덧셈 계층 코드 구현"]},{"cell_type":"code","execution_count":null,"id":"647112c7","metadata":{"id":"647112c7"},"outputs":[],"source":["class AddLayer:\n","    def __init__(self):\n","        pass\n","\n","    def forward(self, x, y):\n","        out = x + y\n","        return out\n","\n","    def backward(self, dout):\n","        dx = dout * 1\n","        dy = dout * 1\n","        return dx, dy"]},{"cell_type":"markdown","id":"c72a4fd2","metadata":{"id":"c72a4fd2"},"source":["### 4.2 곱셈 계층 코드 구현"]},{"cell_type":"code","execution_count":null,"id":"9257d39e","metadata":{"id":"9257d39e"},"outputs":[],"source":["class MulLayer:\n","    def __init__(self):\n","        self.x = None\n","        self.y = None\n","\n","    def forward(self, x, y):\n","        self.x = x\n","        self.y = y\n","        out = x * y\n","        return out\n","\n","    def backward(self, dout):\n","        dx = dout * self.y  # x와 y를 바꾼다.\n","        dy = dout * self.x\n","        return dx, dy"]},{"cell_type":"markdown","id":"11dc0a24","metadata":{"id":"11dc0a24"},"source":["### 4.3 사과 쇼핑 계층 실행"]},{"cell_type":"markdown","id":"98cddd4b","metadata":{"id":"98cddd4b"},"source":["- 사과 2개 구입\n","<img src=\"./images/fig_5-16.png\" width=\"500\"/>"]},{"cell_type":"code","execution_count":null,"id":"19ee9751","metadata":{"id":"19ee9751"},"outputs":[],"source":["# 입력값 설정\n","apple = 100\n","apple_num = 2\n","\n","tax = 1.1"]},{"cell_type":"code","execution_count":null,"id":"cf4148c3","metadata":{"id":"cf4148c3"},"outputs":[],"source":["# 곱셈 계층 생성\n","mul_apple_layer = MulLayer()\n","mul_tax_layer   = MulLayer()"]},{"cell_type":"code","execution_count":null,"id":"38f186b7","metadata":{"id":"38f186b7"},"outputs":[],"source":["# forward\n","apple_price = mul_apple_layer.forward(apple, apple_num)\n","price       = mul_tax_layer.forward(apple_price, tax)"]},{"cell_type":"code","execution_count":null,"id":"c99c86e6","metadata":{"id":"c99c86e6"},"outputs":[],"source":["# backward\n","dprice = 1\n","dapple_price, dtax = mul_tax_layer.backward(dprice)\n","dapple, dapple_num = mul_apple_layer.backward(dapple_price)"]},{"cell_type":"code","execution_count":null,"id":"ad1d9195","metadata":{"id":"ad1d9195","outputId":"df9002b4-4de4-47ee-9559-600b08c0c2b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["price: 220\n","dApple: 2.2\n","dApple_num: 110\n","dTax: 200\n"]}],"source":["# 출력\n","print('price:', int(price))\n","print('dApple:', dapple)\n","print('dApple_num:', int(dapple_num))\n","print('dTax:', dtax)"]},{"cell_type":"markdown","id":"d35233d1","metadata":{"id":"d35233d1"},"source":["### 4.4 사과, 귤 쇼핑 계층 실행"]},{"cell_type":"markdown","id":"1352bf02","metadata":{"id":"1352bf02"},"source":["- 사과 2개, 귤 3개 구입\n","<img src=\"./images/fig_5-17.png\" width=\"500\"/>"]},{"cell_type":"code","execution_count":null,"id":"494fd02f","metadata":{"id":"494fd02f"},"outputs":[],"source":["# 입력값 설정\n","apple = 100\n","apple_num = 2\n","\n","orange = 150\n","orange_num = 3\n","\n","tax = 1.1"]},{"cell_type":"code","execution_count":null,"id":"fd286d82","metadata":{"id":"fd286d82"},"outputs":[],"source":["# 곱셈 계층, 덧셈 계층 생성\n","mul_apple_layer  = MulLayer()\n","mul_orange_layer = MulLayer()\n","\n","add_apple_orange_layer = AddLayer()\n","\n","mul_tax_layer = MulLayer()"]},{"cell_type":"code","execution_count":null,"id":"f2d0a463","metadata":{"id":"f2d0a463"},"outputs":[],"source":["# forward\n","apple_price  = mul_apple_layer.forward(apple, apple_num)               # (1)\n","orange_price = mul_orange_layer.forward(orange, orange_num)            # (2)\n","\n","all_price = add_apple_orange_layer.forward(apple_price, orange_price)  # (3)\n","price     = mul_tax_layer.forward(all_price, tax)                      # (4)"]},{"cell_type":"code","execution_count":null,"id":"d0905f07","metadata":{"id":"d0905f07"},"outputs":[],"source":["# backward\n","dprice = 1\n","dall_price, dtax = mul_tax_layer.backward(dprice)                          # (4)\n","dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)  # (3)\n","dorange, dorange_num = mul_orange_layer.backward(dorange_price)            # (2)\n","dapple, dapple_num = mul_apple_layer.backward(dapple_price)                # (1)"]},{"cell_type":"code","execution_count":null,"id":"a663aed3","metadata":{"id":"a663aed3","outputId":"114cadc0-d061-41c7-ed76-cd70c87c9293"},"outputs":[{"name":"stdout","output_type":"stream","text":["price: 715\n","dApple: 2.2\n","dApple_num: 110\n","dOrange: 3.3000000000000003\n","dOrange_num: 165\n","dTax: 650\n"]}],"source":["# 출력\n","print('price:', int(price))\n","\n","print('dApple:', dapple)\n","print('dApple_num:', int(dapple_num))\n","print('dOrange:', dorange)\n","print('dOrange_num:', int(dorange_num))\n","print('dTax:', dtax)"]},{"cell_type":"markdown","id":"1ef1eede","metadata":{"id":"1ef1eede"},"source":["# 5 활성화 함수 계층 코드 구현\n","- ReLU\n","- Sigmoid"]},{"cell_type":"markdown","id":"20e66932","metadata":{"id":"20e66932"},"source":["### 5.1 ReLU 계층 코드 구현\n","\n","- ReLU 함수 수식\n","<img src=\"./images/e_5.7.png\" width=\"150\"/>\n","\n","- ReLU 함수 미분\n","<img src=\"./images/e_5.8.png\" width=\"150\"/>\n","\n","- ReLU 계층의 계산 그래프\n","<img src=\"./images/fig_5-18.png\" width=\"500\"/>"]},{"cell_type":"markdown","id":"9cf770e3","metadata":{"id":"9cf770e3"},"source":["#### ReLU 계층 코드 구현"]},{"cell_type":"code","execution_count":null,"id":"005ebd6a","metadata":{"id":"005ebd6a"},"outputs":[],"source":["class Relu:\n","    def __init__(self):\n","        self.mask = None\n","\n","    def forward(self, x):\n","        self.mask = (x <= 0)\n","        out = x.copy()\n","        out[self.mask] = 0\n","        return out\n","\n","    def backward(self, dout):\n","        dout[self.mask] = 0\n","        dx = dout\n","        return dx"]},{"cell_type":"markdown","id":"aa8638cf","metadata":{"id":"aa8638cf"},"source":["#### <참고> mask 활용 예제"]},{"cell_type":"code","execution_count":null,"id":"a5e9ed73","metadata":{"id":"a5e9ed73","outputId":"fb3b0fa1-f7e4-4021-cd59-109d02b479d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 1.  -0.5]\n"," [-2.   3. ]]\n"]}],"source":["x = np.array([[1.0, -0.5], [-2.0, 3.0]])\n","print(x)"]},{"cell_type":"code","execution_count":null,"id":"c617b9be","metadata":{"id":"c617b9be","outputId":"35c82449-50aa-449b-d2a1-0ca427ad7e8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[False  True]\n"," [ True False]]\n"]}],"source":["mask = (x <= 0)\n","print(mask)"]},{"cell_type":"code","execution_count":null,"id":"410c7350","metadata":{"id":"410c7350","outputId":"024f072f-79b2-4604-fc1c-40c94455fd50"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1. 0.]\n"," [0. 3.]]\n"]}],"source":["x[mask] = 0\n","print(x)"]},{"cell_type":"markdown","id":"06e64fc5","metadata":{"id":"06e64fc5"},"source":["### 5.2 Sigmoid 계층 코드 구현\n","\n","- Sigmoid 함수 수식\n","<img src=\"./images/e_5.9.png\" width=\"200\"/>\n","\n","- Sigmoid 계층의 계산 그래프(순전파)\n","<img src=\"./images/fig_5-19.png\" width=\"600\"/>\n","\n","- Sigmoid 계층의 계산 그래프(역전파)\n","<img src=\"./images/fig_5-20.png\" width=\"600\"/>\n","\n","- Sigmoid 계층의 계산 그래프(간소화 버전)\n","<img src=\"./images/fig_5-21.png\" width=\"300\"/>\n","\n","- Sigmoid 함수 미분\n","<img src=\"./images/e_5.12.png\" width=\"400\"/>\n","\n","- Sigmoid 계층의 계산 그래프: 순전파의 출력 y 만으로 계산 가능\n","<img src=\"./images/fig_5-22.png\" width=\"300\"/>"]},{"cell_type":"markdown","id":"3d9b2458","metadata":{"id":"3d9b2458"},"source":["#### Sigmoid 계층 코드 구현"]},{"cell_type":"code","execution_count":null,"id":"64f48ca0","metadata":{"id":"64f48ca0"},"outputs":[],"source":["class Sigmoid:\n","    def __init__(self):\n","        self.out = None\n","\n","    def forward(self, x):\n","        out = sigmoid(x)\n","        self.out = out    # 순전파의 출력 보관 후 역전파때 사용\n","        return out\n","\n","    def backward(self, dout):\n","        dx = dout * (1.0 - self.out) * self.out\n","        return dx"]},{"cell_type":"markdown","id":"1f282029","metadata":{"id":"1f282029"},"source":["# 6 Affine/Softmax 계층 코드 구현"]},{"cell_type":"markdown","id":"b611b696","metadata":{"id":"b611b696"},"source":["### 6.1 Affine 계층 코드 구현"]},{"cell_type":"markdown","id":"6a99f8a3","metadata":{"id":"6a99f8a3"},"source":["- Affine 계층의 계산 그래프(순전파): 변수가 행렬\n","<img src=\"./images/fig_5-24.png\" width=\"300\"/>"]},{"cell_type":"markdown","id":"3258c011","metadata":{"id":"3258c011"},"source":["- Affine 계층 미분\n","<img src=\"./images/e_5.13.png\" width=\"150\"/>"]},{"cell_type":"markdown","id":"6e350127","metadata":{"id":"6e350127"},"source":["- 행렬과 전치 행렬\n","<img src=\"./images/e_5.14.png\" width=\"150\"/>"]},{"cell_type":"markdown","id":"50527b90","metadata":{"id":"50527b90"},"source":["- Affine 계층의 계산 그래프(역전파): 변수가 행렬\n","<img src=\"./images/fig_5-25.png\" width=\"500\"/>"]},{"cell_type":"markdown","id":"46f09d5c","metadata":{"id":"46f09d5c"},"source":["- 변수의 형상\n","<img src=\"./images/e_5.15.png\" width=\"300\"/>"]},{"cell_type":"markdown","id":"1dd2650d","metadata":{"id":"1dd2650d"},"source":["- 배치용 Affine 계층의 계산 그래프\n","<img src=\"./images/fig_5-27.png\" width=\"500\"/>"]},{"cell_type":"markdown","id":"9715faf5","metadata":{"id":"9715faf5"},"source":["#### Affine 계층 코드 구현"]},{"cell_type":"code","execution_count":null,"id":"f3572545","metadata":{"id":"f3572545"},"outputs":[],"source":["class Affine:\n","    def __init__(self, W, b):\n","        self.W = W\n","        self.b = b\n","        self.x = None\n","        self.dW = None\n","        self.db = None\n","\n","    def forward(self, x):\n","        self.x = x\n","        out = np.dot(self.x, self.W) + self.b\n","        return out\n","\n","    def backward(self, dout):\n","        dx = np.dot(dout, self.W.T)\n","        self.dW = np.dot(self.x.T, dout)\n","        self.db = np.sum(dout, axis=0)\n","        return dx"]},{"cell_type":"markdown","id":"3bc83e6c","metadata":{"id":"3bc83e6c"},"source":["### 6.2 Softmax 계층 코드 구현\n","\n","- Softmax 계층의 출력\n","<img src=\"./images/fig_5-28.png\" width=\"500\"/>\n","\n","- Softmax-with-Loss 계층의 계산 그래프\n","<img src=\"./images/fig_5-30.png\" width=\"400\"/>"]},{"cell_type":"markdown","id":"3afe3804","metadata":{"id":"3afe3804"},"source":["#### Softmax-with-Loss 계층 코드 구현"]},{"cell_type":"code","execution_count":null,"id":"c1d69aa8","metadata":{"id":"c1d69aa8"},"outputs":[],"source":["class SoftmaxWithLoss:\n","    def __init__(self):\n","        self.loss = None # 손실함수\n","        self.y = None    # softmax의 출력\n","        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n","\n","    def forward(self, x, t):\n","        self.t = t\n","        self.y = softmax(x)\n","        self.loss = cross_entropy_error(self.y, self.t)\n","        return self.loss\n","\n","    def backward(self, dout=1):\n","        batch_size = self.t.shape[0]\n","        dx = (self.y - self.t) / batch_size\n","        return dx"]},{"cell_type":"markdown","id":"91ca8ed1","metadata":{"id":"91ca8ed1"},"source":["# 7 오차 역전파 코드 구현"]},{"cell_type":"markdown","id":"6ce92d47","metadata":{"id":"6ce92d47"},"source":["### 7.1 오차 역전파를 적용한 신경망 코드 구현"]},{"cell_type":"code","execution_count":null,"id":"4134a4d1","metadata":{"id":"4134a4d1"},"outputs":[],"source":["from common.layers import *\n","from common.gradient import numerical_gradient\n","from collections import OrderedDict\n","\n","class TwoLayerNet:\n","\n","    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n","        # 가중치 초기화\n","        self.params = {}\n","        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n","        self.params['b1'] = np.zeros(hidden_size)\n","        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n","        self.params['b2'] = np.zeros(output_size)\n","\n","        # 계층 생성\n","        self.layers = OrderedDict()\n","        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n","        self.layers['Relu1'] = Relu()\n","        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n","\n","        self.lastLayer = SoftmaxWithLoss()\n","\n","    def predict(self, x):\n","        for layer in self.layers.values():\n","            x = layer.forward(x)\n","\n","        return x\n","\n","    # x : 입력 데이터, t : 정답 레이블\n","    def loss(self, x, t):\n","        y = self.predict(x)\n","        return self.lastLayer.forward(y, t)\n","\n","    def accuracy(self, x, t):\n","        y = self.predict(x)\n","        y = np.argmax(y, axis=1)\n","        if t.ndim != 1 : t = np.argmax(t, axis=1)\n","\n","        accuracy = np.sum(y == t) / float(x.shape[0])\n","        return accuracy\n","\n","    # x : 입력 데이터, t : 정답 레이블\n","    def numerical_gradient(self, x, t):\n","        loss_W = lambda W: self.loss(x, t)\n","\n","        grads = {}\n","        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n","        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n","        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n","        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n","\n","        return grads\n","\n","    def gradient(self, x, t):\n","        # forward\n","        self.loss(x, t)\n","\n","        # backward\n","        dout = 1\n","        dout = self.lastLayer.backward(dout)\n","\n","        layers = list(self.layers.values())\n","        layers.reverse()\n","        for layer in layers:\n","            dout = layer.backward(dout)\n","\n","        # 결과 저장\n","        grads = {}\n","        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n","        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n","\n","        return grads"]},{"cell_type":"markdown","id":"6a52f8c3","metadata":{"id":"6a52f8c3"},"source":["### 7.2 수치 미분 - 오차 역전파 기울기 비교"]},{"cell_type":"code","execution_count":null,"id":"1c478dee","metadata":{"id":"1c478dee"},"outputs":[],"source":["from dataset.mnist import load_mnist\n","\n","# 데이터 읽기\n","(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)"]},{"cell_type":"code","execution_count":null,"id":"1081eb49","metadata":{"id":"1081eb49","outputId":"ebb0def0-4a17-485f-ac00-b8a3d697be81"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: total: 0 ns\n","Wall time: 0 ns\n"]}],"source":["%time\n","network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n","\n","x_batch = x_train[:3]\n","t_batch = t_train[:3]\n","\n","# 수치 미분 사용\n","grad_numerical = network.numerical_gradient(x_batch, t_batch)\n","\n","# 오차 역전파 사용\n","grad_backprop  = network.gradient(x_batch, t_batch)"]},{"cell_type":"code","execution_count":null,"id":"4a6c1ccb","metadata":{"id":"4a6c1ccb","outputId":"31fd5f32-c9c8-4ea0-c4b9-e3526a4af09e"},"outputs":[{"name":"stdout","output_type":"stream","text":["W1:4.872482638427244e-10\n","b1:2.9889343011897923e-09\n","W2:5.904457854753626e-09\n","b2:1.3932372812663908e-07\n"]}],"source":["# 각 가중치의 절대 오차의 평균을 구한다.\n","for key in grad_numerical.keys():\n","    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n","    print(key + ':' + str(diff))"]},{"cell_type":"markdown","id":"d96a7b4b","metadata":{"id":"d96a7b4b"},"source":["### 7.3 오차 역전파를 사용한 신경망 학습 코드 구현"]},{"cell_type":"code","execution_count":null,"id":"3c8701ca","metadata":{"id":"3c8701ca"},"outputs":[],"source":["from dataset.mnist import load_mnist\n","\n","# 데이터 읽기\n","(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)"]},{"cell_type":"code","execution_count":null,"id":"322cfd2a","metadata":{"id":"322cfd2a"},"outputs":[],"source":["# 입력값 설정\n","iters_num = 10000\n","train_size = x_train.shape[0]\n","batch_size = 100\n","learning_rate = 0.1"]},{"cell_type":"code","execution_count":null,"id":"7b190ed7","metadata":{"id":"7b190ed7","outputId":"74876bc2-e21e-4bcf-a061-252938084789","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<000> train acc: 0.117, test acc: 0.118\n","<001> train acc: 0.904, test acc: 0.909\n","<002> train acc: 0.923, test acc: 0.923\n","<003> train acc: 0.935, test acc: 0.936\n","<004> train acc: 0.945, test acc: 0.943\n","<005> train acc: 0.952, test acc: 0.951\n","<006> train acc: 0.956, test acc: 0.955\n","<007> train acc: 0.961, test acc: 0.959\n","<008> train acc: 0.964, test acc: 0.960\n","<009> train acc: 0.968, test acc: 0.965\n","<010> train acc: 0.970, test acc: 0.966\n","<011> train acc: 0.971, test acc: 0.967\n","<012> train acc: 0.974, test acc: 0.967\n","<013> train acc: 0.974, test acc: 0.966\n","<014> train acc: 0.975, test acc: 0.968\n","<015> train acc: 0.978, test acc: 0.972\n","<016> train acc: 0.979, test acc: 0.971\n","CPU times: total: 45.2 s\n","Wall time: 35.4 s\n"]}],"source":["%%time\n","train_loss_list = []\n","train_acc_list = []\n","test_acc_list = []\n","\n","iter_per_epoch = max(train_size / batch_size, 1)\n","\n","# 네트워크 생성\n","network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n","\n","for i in range(iters_num):\n","    # 미니배치 획득\n","    batch_mask = np.random.choice(train_size, batch_size)\n","    x_batch = x_train[batch_mask]\n","    t_batch = t_train[batch_mask]\n","\n","    # 기울기 계산\n","    #grad = network.numerical_gradient(x_batch, t_batch) # 수치 미분 방식\n","    grad = network.gradient(x_batch, t_batch) # 오차역전파법 방식(훨씬 빠르다)\n","\n","    # 매개변수 갱신\n","    for key in ('W1', 'b1', 'W2', 'b2'):\n","        network.params[key] -= learning_rate * grad[key]\n","\n","    # 학습 경과 기록\n","    loss = network.loss(x_batch, t_batch)\n","    train_loss_list.append(loss)\n","\n","    # 1에폭당 정확도 계산\n","    if i % iter_per_epoch == 0:\n","        train_acc = network.accuracy(x_train, t_train)\n","        test_acc = network.accuracy(x_test, t_test)\n","        train_acc_list.append(train_acc)\n","        test_acc_list.append(test_acc)\n","        print(f'<{int(i//iter_per_epoch):03}> train acc: {train_acc:.3f}, test acc: {test_acc:.3f}')"]},{"cell_type":"markdown","id":"f46fba2a","metadata":{"id":"f46fba2a"},"source":["# 정리"]},{"cell_type":"markdown","id":"5daf8f53","metadata":{"id":"5daf8f53"},"source":["- 계산그래프를 이용하연 계산 과정을 시각적으로 파악할수 있다.\n","- 계산 그래프의 노드는 국소적 계산으로 구성된다. 국소적 계산을 조합해 전체 계산을 구성한다.\n","- 계산 그래프의 순전파는 통상의 계산을 수행한다. 한편, 계산 그래프의 역전파로는 각 노드의 미분을 구할 수 있다.\n","- 신경망의 구성 요소를 계층으로 구현하여 기울기를 효율적으로 계산할수 있다(오차역전파법).\n","- 수치 미분과 오차역전파법의 결과를 비교하면 오차역전파법의 구현에 잘못이 없는지 확인할 수 있다(기울기 확인)."]},{"cell_type":"code","execution_count":null,"id":"fd942b0b","metadata":{"id":"fd942b0b"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"f076fa13","metadata":{"id":"f076fa13"},"source":["---"]},{"cell_type":"markdown","id":"97a2126e","metadata":{"id":"97a2126e"},"source":["# NOTE  \n","   \n","[Backpropagation](https://wikidocs.net/37406)  \n","  \n","- 사과 쇼핑의 역전파 예\n","<img src=\"./images/fig_5-14.png\" width=\"500\"/>  \n","  \n","- 연쇄법칙(Chain rule) 적용\n","<img src=\"./images/e_5.2.png\" width=\"150\"/>  \n","  \n","- 각 함수 미분\n","<img src=\"./images/e_5.3.png\" width=\"100\"/>  \n","  \n","- 합성 함수 미분 계산 - 치환 변수 환원( $t = x + y$ )\n","<img src=\"./images/e_5.4.png\" width=\"300\"/>  \n","  \n","---  \n","  \n","Input Layer -> Hidden Layer -> Output Layer => Y  \n","  \n","Input ~ Hidden에서 w1가 쓰이고, Hidden ~ Output에서 w2가 쓰인다고 하자.  \n","또한, Cost Function은 t-y1, t-y2, ..., t-y100을 전부 이용해서 만든 잔차의 함수이다.(t가 정답, y가 예측값)  \n","  \n","y값을 찾는 과정을 추론(Inference, Predict) 혹은 순전파라고 하며, 반대로 거슬러 올라가 w값을 찾는 것을 학습(Training) 혹은 역전파라고 한다.  \n","  \n","원래는 역전파를 안 쓰고, 위에서 소개한 연쇄법칙(Chain rule)을 이용하여 dC/dw(w값 변화에 따른 최종 결과값 Cost Function의 변화량을 의미한다.)를 구하면 됐다.  \n","하지만, dC/dw를 구하기까지 chain에 속해있는 dC/dA, dA/dB, dB/dD, dD/dw들이 문제였는데..  \n","  \n","dC/dA는 A로 표현이 되고, dA/dB는 B로 표현이 되고, dB/dD는 D로 표현이 되고, dD/dw는 w로 표현이 된다.  \n","우리는 w로 표현된 C를 구해야 하니까, w와 A, B, D간의 관계식을 통해 각각 치환하여 모두 w로 표현하는 과정이 필요했다.  \n","  \n","하지만 이 치환이 현실적으로 불가능하다. 식이 너무 많다.  \n","  \n","---\n","  \n","그래서 우리는 아래의 방법 (오차역전파)를 사용하기로 했다.  \n","  \n","우리가 관심있는 것은 w값의 변화에 따른 C값의 변화량인 dC/dw이다.  \n","왜냐? dC/dw가 가장 작게 나오는 w값이 우리가 찾는 최적의 w값임을 증명하기 때문이다!  \n","  \n","우선 임의의 w1을 이용해서 D를 구한다. D로 B를 구하고, B로 A를 구한 뒤, A로 C를 구한다. 즉, 순전파를 한다.  \n","C를 구했으면, C에서 A로 가는 변화량(기울기)를 구한다. 또, 역으로 A에서 B로의 변화량인 기울기를 구하고, B에서 D로의 기울기, D에서 w로의 기울기를 구한다.  \n","  \n","이 기울기들을 chain하면 최종적으로 dC/dw를 알 수 있다.  \n","원한다면, dC/dB, dC/dA들도 알 수 있다.(chain을 중간에 끊으면 됨.)  \n","  \n","단, 우리가 방금 구한 dC/dw는 w1에 대해서만 옳은 값이다.  \n","즉, w2에 대해서는 다시 순전파해서 값들 싹 구하고, 역으로 올라오면서 기울기 다 구해서 chain해서 dC/dw 구해야 한다.  \n","매우 귀찮지만, 적어도 치환의 어려움과 복잡성으로 사실상 계산이 복잡한 기존의 방식보다는 컴퓨터가 좋아한다.   \n","  \n","이를 오차역전파라고 한다.  "]},{"cell_type":"markdown","id":"eef25a0f","metadata":{"id":"eef25a0f"},"source":["### 4.1 덧셈 계층 코드 구현"]},{"cell_type":"code","execution_count":null,"id":"2030e395","metadata":{"id":"2030e395"},"outputs":[],"source":["class AddLayer:\n","    def __init__(self):\n","        pass\n","\n","    def forward(self, x, y):\n","        out = x + y\n","        return out\n","\n","    def backward(self, dout):\n","        dx = dout * 1\n","        dy = dout * 1\n","        return dx, dy"]},{"cell_type":"markdown","id":"6857b117","metadata":{"id":"6857b117"},"source":["### 4.2 곱셈 계층 코드 구현"]},{"cell_type":"code","execution_count":null,"id":"f3f45dbd","metadata":{"id":"f3f45dbd"},"outputs":[],"source":["class MulLayer:\n","    def __init__(self):\n","        self.x = None\n","        self.y = None\n","\n","    def forward(self, x, y):\n","        self.x = x\n","        self.y = y\n","        out = x * y\n","        return out\n","\n","    def backward(self, dout):\n","        dx = dout * self.y  # x와 y를 바꾼다.\n","        dy = dout * self.x\n","        return dx, dy"]},{"cell_type":"markdown","id":"4f4b860d","metadata":{"id":"4f4b860d"},"source":["### 5.1 ReLU 계층 코드 구현\n","\n","- ReLU 함수 수식\n","<img src=\"./images/e_5.7.png\" width=\"150\"/>\n","\n","- ReLU 함수 미분\n","<img src=\"./images/e_5.8.png\" width=\"150\"/>\n","\n","- ReLU 계층의 계산 그래프\n","<img src=\"./images/fig_5-18.png\" width=\"500\"/>"]},{"cell_type":"code","execution_count":null,"id":"81494923","metadata":{"id":"81494923"},"outputs":[],"source":["class Relu:\n","    def __init__(self):\n","        self.mask = None\n","\n","    def forward(self, x):\n","        self.mask = (x <= 0)\n","        out = x.copy()\n","        out[self.mask] = 0\n","        return out\n","\n","    def backward(self, dout):\n","        dout[self.mask] = 0\n","        dx = dout\n","        return dx"]},{"cell_type":"markdown","id":"b25831fd","metadata":{"id":"b25831fd"},"source":["### 5.2 Sigmoid 계층 코드 구현\n","\n","- Sigmoid 함수 수식\n","<img src=\"./images/e_5.9.png\" width=\"200\"/>\n","\n","- Sigmoid 계층의 계산 그래프(순전파)\n","<img src=\"./images/fig_5-19.png\" width=\"600\"/>\n","\n","- Sigmoid 계층의 계산 그래프(역전파)\n","<img src=\"./images/fig_5-20.png\" width=\"600\"/>\n","\n","- Sigmoid 계층의 계산 그래프(간소화 버전)\n","<img src=\"./images/fig_5-21.png\" width=\"300\"/>\n","\n","- Sigmoid 함수 미분\n","<img src=\"./images/e_5.12.png\" width=\"400\"/>\n","\n","- Sigmoid 계층의 계산 그래프: 순전파의 출력 y 만으로 계산 가능\n","<img src=\"./images/fig_5-22.png\" width=\"300\"/>"]},{"cell_type":"code","execution_count":null,"id":"cc117a0a","metadata":{"id":"cc117a0a"},"outputs":[],"source":["class Sigmoid:\n","    def __init__(self):\n","        self.out = None\n","\n","    def forward(self, x):\n","        out = sigmoid(x)\n","        self.out = out    # 순전파의 출력 보관 후 역전파때 사용\n","        return out\n","\n","    def backward(self, dout):\n","        dx = dout * (1.0 - self.out) * self.out\n","        return dx"]},{"cell_type":"markdown","id":"f628c813","metadata":{"id":"f628c813"},"source":["### 6.2 Softmax 계층 코드 구현\n","\n","- Softmax 계층의 출력\n","<img src=\"./images/fig_5-28.png\" width=\"500\"/>\n","\n","- Softmax-with-Loss 계층의 계산 그래프\n","<img src=\"./images/fig_5-30.png\" width=\"400\"/>  \n","\n","Softmax with Loss 계층의 계산 그래프에서 `y - t`는 손실(오차)을 나타냅니다. 이 계층은 주로 분류 문제에서 사용되며, 입력으로 들어온 데이터를 확률로 변환한 후 이 확률과 실제 정답과의 차이를 계산합니다.\n","\n","Softmax with Loss 계층의 구성은 다음과 같습니다:\n","\n","1. **Softmax 계층:** 입력 데이터를 확률 분포로 변환합니다. 즉, 주어진 입력에 대한 각 클래스의 확률을 계산합니다.\n","\n","2. **Cross-Entropy Loss (교차 엔트로피 손실):** Softmax에서 얻은 확률 분포와 실제 정답 분포(원-핫 인코딩된 레이블) 간의 차이를 측정합니다. 이는 모델의 예측이 실제와 얼마나 다른지를 나타냅니다.\n","\n","이때 `y`는 Softmax 계층의 출력(모델의 예측), `t`는 실제 정답 분포(레이블)입니다. 따라서 `y - t`는 예측과 실제 간의 차이를 나타내며, 이 차이가 작을수록 손실은 작아지고 모델의 성능이 좋다고 판단됩니다. 이러한 손실을 최소화하면서 모델을 학습시키는 것이 분류 문제에서의 주요 목표입니다."]},{"cell_type":"code","execution_count":null,"id":"980b361b","metadata":{"id":"980b361b"},"outputs":[],"source":["class SoftmaxWithLoss:\n","    def __init__(self):\n","        self.loss = None # 손실함수\n","        self.y = None    # softmax의 출력\n","        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n","\n","    def forward(self, x, t):\n","        self.t = t\n","        self.y = softmax(x)\n","        self.loss = cross_entropy_error(self.y, self.t)\n","        return self.loss\n","\n","    def backward(self, dout=1):\n","        batch_size = self.t.shape[0]\n","        dx = (self.y - self.t) / batch_size\n","        return dx"]},{"cell_type":"markdown","id":"dc68d637","metadata":{"id":"dc68d637"},"source":["### 7.1 오차 역전파를 적용한 신경망 코드 구현"]},{"cell_type":"code","execution_count":null,"id":"575d6b71","metadata":{"id":"575d6b71"},"outputs":[],"source":["from common.layers import *\n","from common.gradient import numerical_gradient\n","from collections import OrderedDict\n","\n","class TwoLayerNet:\n","\n","    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n","        # 가중치 초기화\n","        self.params = {}\n","        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n","        self.params['b1'] = np.zeros(hidden_size)\n","        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n","        self.params['b2'] = np.zeros(output_size)\n","\n","        # 계층 생성\n","        self.layers = OrderedDict()\n","        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n","        self.layers['Relu1'] = Relu()\n","        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n","\n","        self.lastLayer = SoftmaxWithLoss()\n","\n","    def predict(self, x):\n","        for layer in self.layers.values():\n","            x = layer.forward(x)\n","\n","        return x\n","\n","    # x : 입력 데이터, t : 정답 레이블\n","    def loss(self, x, t):\n","        y = self.predict(x)\n","        return self.lastLayer.forward(y, t)\n","\n","    def accuracy(self, x, t):\n","        y = self.predict(x)\n","        y = np.argmax(y, axis=1)\n","        if t.ndim != 1 : t = np.argmax(t, axis=1)\n","\n","        accuracy = np.sum(y == t) / float(x.shape[0])\n","        return accuracy\n","\n","    # x : 입력 데이터, t : 정답 레이블\n","    def numerical_gradient(self, x, t):\n","        loss_W = lambda W: self.loss(x, t)\n","\n","        grads = {}\n","        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n","        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n","        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n","        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n","\n","        return grads\n","\n","    def gradient(self, x, t):\n","        # forward\n","        self.loss(x, t)\n","\n","        # backward\n","        dout = 1\n","        dout = self.lastLayer.backward(dout)\n","\n","        layers = list(self.layers.values())\n","        layers.reverse()\n","        for layer in layers:\n","            dout = layer.backward(dout)\n","\n","        # 결과 저장\n","        grads = {}\n","        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n","        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n","\n","        return grads"]},{"cell_type":"markdown","id":"8a533eb3","metadata":{"id":"8a533eb3"},"source":["### 7.3 오차 역전파를 사용한 신경망 학습 코드 구현"]},{"cell_type":"code","execution_count":null,"id":"c81e7850","metadata":{"id":"c81e7850"},"outputs":[],"source":["from dataset.mnist import load_mnist\n","\n","# 데이터 읽기\n","(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)"]},{"cell_type":"code","execution_count":null,"id":"116ef406","metadata":{"id":"116ef406"},"outputs":[],"source":["# 입력값 설정\n","iters_num = 10000\n","train_size = x_train.shape[0]\n","batch_size = 100\n","learning_rate = 0.1"]},{"cell_type":"code","execution_count":null,"id":"496e3a12","metadata":{"id":"496e3a12","outputId":"ccf13815-7b1f-4fd5-e717-dbcbee8709b3","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<000> train acc: 0.139, test acc: 0.141\n","<001> train acc: 0.904, test acc: 0.909\n","<002> train acc: 0.924, test acc: 0.927\n","<003> train acc: 0.935, test acc: 0.935\n","<004> train acc: 0.945, test acc: 0.945\n","<005> train acc: 0.952, test acc: 0.951\n","<006> train acc: 0.957, test acc: 0.953\n","<007> train acc: 0.961, test acc: 0.957\n","<008> train acc: 0.965, test acc: 0.959\n","<009> train acc: 0.968, test acc: 0.961\n","<010> train acc: 0.970, test acc: 0.964\n","<011> train acc: 0.972, test acc: 0.966\n","<012> train acc: 0.974, test acc: 0.967\n","<013> train acc: 0.975, test acc: 0.967\n","<014> train acc: 0.976, test acc: 0.967\n","<015> train acc: 0.978, test acc: 0.968\n","<016> train acc: 0.978, test acc: 0.970\n","CPU times: total: 49 s\n","Wall time: 39.3 s\n"]}],"source":["%%time\n","train_loss_list = []\n","train_acc_list = []\n","test_acc_list = []\n","\n","iter_per_epoch = max(train_size / batch_size, 1)\n","\n","# 네트워크 생성\n","network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10) #TwoLayerNet은 위에서 미리 만들어둔 클래스이다.\n","\n","for i in range(iters_num):\n","    # 미니배치 획득\n","    batch_mask = np.random.choice(train_size, batch_size)\n","    x_batch = x_train[batch_mask]\n","    t_batch = t_train[batch_mask]\n","\n","    # 기울기 계산\n","    #grad = network.numerical_gradient(x_batch, t_batch) # 수치 미분 방식\n","    grad = network.gradient(x_batch, t_batch) # 오차역전파법 방식(훨씬 빠르다)\n","\n","    # 매개변수 갱신\n","    for key in ('W1', 'b1', 'W2', 'b2'):\n","        network.params[key] -= learning_rate * grad[key]\n","\n","    # 학습 경과 기록\n","    loss = network.loss(x_batch, t_batch)\n","    train_loss_list.append(loss)\n","\n","    # 1에폭당 정확도 계산\n","    if i % iter_per_epoch == 0:\n","        train_acc = network.accuracy(x_train, t_train)\n","        test_acc = network.accuracy(x_test, t_test)\n","        train_acc_list.append(train_acc)\n","        test_acc_list.append(test_acc)\n","        print(f'<{int(i//iter_per_epoch):03}> train acc: {train_acc:.3f}, test acc: {test_acc:.3f}')"]},{"cell_type":"code","execution_count":null,"id":"810a4484","metadata":{"id":"810a4484"},"outputs":[],"source":["# End of file"]},{"cell_type":"code","execution_count":null,"id":"85afea49","metadata":{"id":"85afea49"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vp":{"vp_config_version":"1.0.0","vp_menu_width":273,"vp_note_display":true,"vp_note_width":263,"vp_position":{"width":541},"vp_section_display":false,"vp_signature":"VisualPython"}},"nbformat":4,"nbformat_minor":5}