{"cells":[{"cell_type":"markdown","id":"be8459af","metadata":{"id":"be8459af"},"source":["# Deep Learning - CNN"]},{"cell_type":"markdown","source":["So far, the structure of our neural network treats all inputs interchangeably.\n","- No relationships between the individual inputs.\n","- Just an ordered set of variables.\n","- We want to incorporate domain knowledge into the architecture of a Neural Network.\n","\n","The convolutional network we discuss here was developed to deal with image data.  \n","Increasingly, these approaches are being applied to more common analytic problems of regression and classification.  \n","\n","CNN은 Convolutional Neural Network의 약자로, 주로 이미지 처리에 사용되는 딥러닝 모델의 한 종류입니다. CNN은 이미지 내에서 패턴을 인식하고 이해하는 데 특히 효과적입니다.  \n","\n","일반적인 Neural Network와의 주요 차이점은 다음과 같습니다:  \n","\n","1. **로컬 연결(Local Connectivity)**: CNN은 입력 이미지의 특정 지역에 대해서만 연결되는 것이 일반적입니다. 이는 합성곱 연산을 통해 입력 이미지의 지역적 특징을 추출하는 데 유리합니다.\n","\n","2. **파라미터 공유(Parameter Sharing)**: CNN에서는 합성곱층에서 사용되는 필터(커널)가 이미지 전체에 대해 공유됩니다. 이는 모델의 학습 파라미터를 줄이고 효율적인 특징 추출을 가능하게 합니다.\n","\n","3. **공간적 계층 구조(Spatial Hierarchies)**: CNN은 여러 층의 합성곱 및 풀링층을 통해 입력 이미지의 공간적 계층 구조를 학습할 수 있습니다. 이를 통해 저수준의 특징에서 고수준의 추상적인 개념까지 학습할 수 있습니다.\n","\n","요약하면, CNN은 이미지 처리에 특화되어 있고, 로컬 연결과 파라미터 공유를 통해 효율적으로 특징을 추출하며, 공간적 계층 구조를 학습하여 이미지 분류, 객체 검출, 분할 등 다양한 작업에 활용됩니다.  \n","\n","CNN에서는 입력 이미지의 각 지역에 대해 별도의 가중치가 적용되고, 이 가중치는 해당 지역의 특징을 인식하는 데 사용됩니다. 이는 전통적인 Fully Connected Neural Network와 달리, 모든 입력과 출력 간에 연결이 있는 것이 아니라, 입력 이미지의 지역적 특징을 고려하여 연결되는 것을 의미합니다. 이로써 CNN은 이미지의 지역적 구조를 인식하고 공간적 계층 구조를 학습할 수 있습니다.\n","\n","203_딥러닝_CNN_image_1은 Input to Output Scheme을, 203_딥러닝_CNN_Image_2는 이미지의 지역정 특징을 강조하는 데 사용되는 방법을 간단하게 표현한 것이다.  \n","\n"],"metadata":{"id":"3GZGlyxGx30j"},"id":"3GZGlyxGx30j"},{"cell_type":"markdown","source":["수용 영역(Receptive field)은 신경망의 특정 뉴런이 입력에 반응하는 영역을 의미합니다. 다시 말해, 특정 뉴런이 활성화되기 위해 필요한 입력 데이터의 영역입니다. 이것은 특정 뉴런이 본 것에 대한 영역이며, 그 뉴런이 인식할 수 있는 영역의 크기를 결정합니다.\n","\n","수용 영역은 이미지 처리에서 자주 사용되는 용어입니다. 예를 들어, 컨볼루션 신경망(Convolutional Neural Network, CNN)에서 각 레이어의 각 뉴런은 입력 이미지의 특정 부분에 반응합니다. 이때 각 뉴런의 수용 영역은 해당 뉴런에 영향을 미치는 입력 이미지의 영역을 나타냅니다.\n","\n","수용 영역의 크기는 신경망의 아키텍처와 레이어의 종류에 따라 달라집니다. 일반적으로 레이어가 깊어질수록 수용 영역의 크기가 커지는 경향이 있습니다. 이는 더 깊은 레이어에서는 더 넓은 영역의 특징을 인식해야 하기 때문입니다.\n","\n","레이어가 깊어질수록 수용 영역의 크기가 커지는 이유는 주로 두 가지 요인에 기인합니다:\n","\n","1. **다단계 특징 추출**: 심층 신경망은 보통 입력 데이터를 다단계로 처리합니다. 첫 번째 층은 입력 데이터의 초기 특징을 감지하고, **이후의 각 층은 이전 층의 특징을 결합하여 더 추상적인 특징을 추출합니다.** 이렇게 다단계로 처리되는 과정에서 각 층은 더 넓은 영역의 특징을 인식하도록 학습됩니다.\n","\n","2. **컨볼루션 연산의 반복**: 컨볼루션 신경망에서는 일반적으로 여러 개의 컨볼루션 층이 쌓여 있습니다. 각 컨볼루션 층은 이전 층의 출력을 입력으로 받아 필터를 적용하여 새로운 특징을 추출합니다. 이렇게 층이 쌓일수록 각 픽셀은 더 많은 컨볼루션 연산을 거치게 되며, 이는 결국 더 넓은 수용 영역을 갖는 특징을 인식하는데 도움이 됩니다.\n","\n","이렇게 레이어가 깊어질수록 수용 영역의 크기가 커지는 것은 신경망이 입력 데이터의 다양한 공간적 특징을 더 잘 이해하고 이를 기반으로 추상적인 표현을 학습할 수 있도록 합니다. 이는 보다 복잡한 문제를 해결하는 데 도움이 되며, 특히 이미지 인식 및 컴퓨터 비전과 같은 작업에서 효과적입니다."],"metadata":{"id":"mQzRKI65ZTRZ"},"id":"mQzRKI65ZTRZ"},{"cell_type":"markdown","id":"c0c93566","metadata":{"id":"c0c93566"},"source":["---"]},{"cell_type":"markdown","id":"827d9166","metadata":{"id":"827d9166"},"source":["# 1 MNIST 손글씨 인식 - CNN"]},{"cell_type":"markdown","id":"5ec0233e","metadata":{"id":"5ec0233e"},"source":["- [CNN(Convolutional Neural Network)](https://gruuuuu.github.io/machine-learning/cnn-doc)"]},{"cell_type":"code","execution_count":null,"id":"f758a8dd","metadata":{"id":"f758a8dd"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.rc('figure', figsize=(10, 6))\n","\n","from matplotlib import rcParams\n","rcParams['font.family'] = 'Gulim'\n","rcParams['font.size'] = 10\n","rcParams['axes.unicode_minus'] = False"]},{"cell_type":"markdown","id":"d9536dc1","metadata":{"id":"d9536dc1"},"source":["#### 패키지 임포트"]},{"cell_type":"code","execution_count":null,"id":"9fe79255","metadata":{"id":"9fe79255"},"outputs":[],"source":["from keras.utils import np_utils\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n","from keras.callbacks import ModelCheckpoint,EarlyStopping\n","\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"id":"194bf488","metadata":{"id":"194bf488"},"outputs":[],"source":["# seed 값 설정\n","np.random.seed(0)\n","tf.random.set_seed(3)"]},{"cell_type":"markdown","id":"fde5a86a","metadata":{"id":"fde5a86a"},"source":["#### 데이터 로드 및 분할"]},{"cell_type":"code","execution_count":null,"id":"b52d69dc","metadata":{"id":"b52d69dc"},"outputs":[],"source":["# MNIST 데이터 불러오기\n","from keras.datasets import mnist\n","\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n","X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n","\n","y_train = np_utils.to_categorical(y_train)\n","y_test = np_utils.to_categorical(y_test)"]},{"cell_type":"markdown","id":"4dec1ca1","metadata":{"id":"4dec1ca1"},"source":["#### 컨볼루션 신경망 모델 생성 및 설정"]},{"cell_type":"code","execution_count":null,"id":"bd286da9","metadata":{"id":"bd286da9"},"outputs":[],"source":["model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'))\n","# 이 층에는 총 32개의 필터가 있으며, 각 필터의 사이즈는 3x3이고, 투입될 사진 사이즈는 28x28이다. 1은 흑백이라 채널1 번으로 한 거.\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(128,  activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(10, activation='softmax'))"]},{"cell_type":"markdown","id":"c7ca65e9","metadata":{"id":"c7ca65e9"},"source":["#### 모델 계층 확인"]},{"cell_type":"code","execution_count":null,"id":"efd9b125","metadata":{"id":"efd9b125","outputId":"c49f97d9-0c63-4ca8-bbd1-a60730041138"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 26, 26, 32)        320       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 12, 12, 64)        0         \n","                                                                 \n"," flatten (Flatten)           (None, 9216)              0         \n","                                                                 \n"," dense (Dense)               (None, 128)               1179776   \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 1,199,882\n","Trainable params: 1,199,882\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","id":"b6453892","metadata":{"id":"b6453892"},"source":["#### 모델 컴파일"]},{"cell_type":"code","execution_count":null,"id":"d408a096","metadata":{"id":"d408a096"},"outputs":[],"source":["model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"markdown","id":"09a3c186","metadata":{"id":"09a3c186"},"source":["#### 모델 업데이트 및 저장 설정"]},{"cell_type":"code","execution_count":null,"id":"b8645a44","metadata":{"id":"b8645a44"},"outputs":[],"source":["modelpath=\"./model/model_mnist_cnn{epoch:02d}-{val_loss:.4f}.hdf5\"\n","checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)"]},{"cell_type":"markdown","id":"d55ae670","metadata":{"id":"d55ae670"},"source":["#### 학습 자동 중단 설정"]},{"cell_type":"code","execution_count":null,"id":"0fe231ec","metadata":{"id":"0fe231ec"},"outputs":[],"source":["early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"]},{"cell_type":"markdown","id":"32b938e0","metadata":{"id":"32b938e0"},"source":["#### 모델 학습 실행 및 저장"]},{"cell_type":"code","execution_count":null,"id":"4f48082a","metadata":{"scrolled":true,"id":"4f48082a"},"outputs":[],"source":["%%time\n","# 30분 소요\n","epoch = 30\n","history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epoch, batch_size=200, verbose=0,\n","                    callbacks=[early_stopping_callback,checkpointer])"]},{"cell_type":"markdown","id":"35b506b0","metadata":{"id":"35b506b0"},"source":["#### 모델 평가"]},{"cell_type":"code","execution_count":null,"id":"c1314b0f","metadata":{"id":"c1314b0f","outputId":"270b781c-8b27-4329-a477-7efe95ad4407"},"outputs":[{"name":"stdout","output_type":"stream","text":["313/313 [==============================] - 8s 21ms/step - loss: 0.1388 - accuracy: 0.9563\n","\n"," Test Accuracy: 0.9563\n"]}],"source":["# 테스트 정확도 출력\n","print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, y_test)[1]))"]},{"cell_type":"markdown","id":"31f5e3a4","metadata":{"id":"31f5e3a4"},"source":["#### 학습 진행 과정\n","- history\n"," - loss: 훈련 손실값\n"," - accuracy: 훈련 정확도\n"," - val_loss: 검증 손실값\n"," - val_accuracy: 검증 정확도"]},{"cell_type":"code","execution_count":null,"id":"a9e28e75","metadata":{"id":"a9e28e75","outputId":"23937959-e8eb-42c7-a77f-34b478bdc24d"},"outputs":[{"ename":"NameError","evalue":"name 'history' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 그래프로 표현\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m],     marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mgrid()\n","\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"]}],"source":["# 그래프로 표현\n","plt.plot(history.history['val_loss'], marker='.', c='red', label='Validation Loss')\n","plt.plot(history.history['loss'],     marker='.', c='blue',label='Train Loss')\n","\n","plt.grid()\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend(loc='upper right')\n","\n","plt.title('학습 진행에 따른 학습 데이터와 검증 데이터의 에러')\n","plt.show()"]},{"cell_type":"markdown","id":"dfd1a8e7","metadata":{"id":"dfd1a8e7"},"source":["#### 결과 예측"]},{"cell_type":"code","execution_count":null,"id":"753d9752","metadata":{"id":"753d9752"},"outputs":[],"source":["# 예측 확률\n","pred_prob = model.predict(X_test)\n","pred_prob"]},{"cell_type":"code","execution_count":null,"id":"123a9315","metadata":{"id":"123a9315"},"outputs":[],"source":["# 결과 예측\n","pred = np.argmax(pred_prob, axis=1).flatten()\n","pred"]},{"cell_type":"markdown","id":"e543ebe2","metadata":{"id":"e543ebe2"},"source":["#### 결과 확인"]},{"cell_type":"code","execution_count":null,"id":"ea695ff1","metadata":{"id":"ea695ff1"},"outputs":[],"source":["plt.imshow(X_test[0].reshape(28,-1))\n","#X_test의 0번째 행의 데이터를 reshape(28x28인데 -1쓴 이유는 자동으로 결정하라는 뜻)해서 image로 보여줘.\n","plt.title(f'Label: {pred[0]}')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"05ef599c","metadata":{"id":"05ef599c"},"outputs":[],"source":["fig, axes = plt.subplots(2, 5, figsize=(10, 5), subplot_kw={'xticks':(), 'yticks': ()})\n","for i, (ax, img) in enumerate(zip(axes.ravel(), X_test[:10].reshape(10, 28,-1))):\n","    ax.imshow(img)\n","    ax.set_xlabel(f'Label: {pred[i]}')"]},{"cell_type":"markdown","id":"da17114e","metadata":{"id":"da17114e"},"source":["#### 결과 평가"]},{"cell_type":"code","execution_count":null,"id":"5884b2f6","metadata":{"id":"5884b2f6"},"outputs":[],"source":["y_test_1d = np.argmax(y_test, axis=1).flatten()"]},{"cell_type":"code","execution_count":null,"id":"0cbdadfc","metadata":{"id":"0cbdadfc"},"outputs":[],"source":["from sklearn.metrics import classification_report\n","print(classification_report(y_test_1d, pred))"]},{"cell_type":"code","execution_count":null,"id":"b008ffbb","metadata":{"id":"b008ffbb"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"f076fa13","metadata":{"id":"f076fa13"},"source":["---"]},{"cell_type":"code","execution_count":null,"id":"810a4484","metadata":{"id":"810a4484"},"outputs":[],"source":["# End of file"]},{"cell_type":"code","execution_count":null,"id":"85afea49","metadata":{"id":"85afea49"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vp":{"vp_config_version":"1.0.0","vp_menu_width":273,"vp_note_display":true,"vp_note_width":263,"vp_position":{"width":541},"vp_section_display":false,"vp_signature":"VisualPython"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}